{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import Word2Vec\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "% matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194439, 9)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse(path): \n",
    "    g = gzip.open(path, 'rb') \n",
    "    for l in g: \n",
    "        yield eval(l) \n",
    "\n",
    "def getDF(path): \n",
    "    i = 0 \n",
    "    df = {} \n",
    "    for d in parse(path): \n",
    "        df[i] = d \n",
    "        i += 1 \n",
    "    return pd.DataFrame.from_dict(df, orient='index') \n",
    "\n",
    "\n",
    "df = getDF('Cell_Phones_and_Accessories_5.json.gz')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Reviews:\n",
    "### 10 helpfulness ratings, 10 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get Asins\n",
    "nr_reviews = df.groupby('asin').size()\n",
    "index_reviews = df.groupby('asin').size().values >= 10\n",
    "asins = nr_reviews[index_reviews].index\n",
    "data_f1 = df.loc[df['asin'].isin(asins),:]\n",
    "\n",
    "#get ratings\n",
    "nr_ratings = data_f1['helpful'].apply(np.sum) >= 10\n",
    "\n",
    "#data\n",
    "data = data_f1.loc[nr_ratings,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Anatomical Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Low Quality Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Stopwords and stemmer.\n",
    "stemmer = PorterStemmer()\n",
    "lemmarizer = LancasterStemmer()\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "## Function to remove stopwords, punctuation and stem text.\n",
    "def clean_text(input_text):\n",
    "    output_text = [stemmer.stem(word.lower().translate(None, string.punctuation)) \\\n",
    "                   for word in input_text.split() if word not in stop_words]\n",
    "    return output_text\n",
    "\n",
    "## Class to yield lines.\n",
    "class LineSet(object):\n",
    "    def __init__(self, input_lines):\n",
    "        self.input_lines = input_lines\n",
    "    def __iter__(self):\n",
    "        for line in self.input_lines:\n",
    "            yield clean_text(line)\n",
    "\n",
    "## Generate word2vec model from reviews.\n",
    "line_set = LineSet(df['reviewText'])\n",
    "model = Word2Vec(line_set, size=200, min_count=8, window=7)\n",
    "\n",
    "## Save and finalize model.\n",
    "model.save('amazon2vec.bin')\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Plot a couple of words.\n",
    "test = ['vendor','iphon','ship','samsung']\n",
    "tsne = TSNE(perplexity=80, n_components=2, init='pca', n_iter=5000)\n",
    "\n",
    "\n",
    "## Plot.\n",
    "plt.figure(1)\n",
    "for t in xrange(len(test)):\n",
    "    word_viz = np.array([model[word[0]] for word in model.most_similar(test[t], topn=20)])\n",
    "    labels = [word[0] for word in model.most_similar(test[t], topn=20)]\n",
    "    low_dim_embs = tsne.fit_transform(word_viz)\n",
    "    \n",
    "    plt.subplot(221 + t)\n",
    "\n",
    "    plt.rcParams['figure.figsize'] = (16.0, 16.0)\n",
    "    plt.title(test[t], size=16)\n",
    "    plt.scatter(low_dim_embs[:, 0], low_dim_embs[:, 1], s=50, c='orange')\n",
    "\n",
    "    for label, x, y in zip(labels, low_dim_embs[:, 0], low_dim_embs[:, 1]):\n",
    "         plt.annotate(label, \n",
    "                     xy = (x, y), xytext = (-10, -15), fontsize=10,\n",
    "                     textcoords = 'offset points', ha = 'right', va = 'bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
